# 大文件上传优化：分片上传的实现与原理

在现代的 Web 应用中，文件上传是一个非常常见的需求。通常情况下，我们可以通过设置 `content-type` 为 `multipart/form-data`，将文件以这种格式传递到服务端，服务端再根据该格式提取数据，获取上传的文件。

然而，当文件体积较大时，上传的过程就会变得非常缓慢。假设上传一个 100MB 的文件需要 3 分钟，那么上传一个 1GB 的文件可能需要 30 分钟。这种情况下，虽然功能上可以完成，但用户体验会非常糟糕。因此，对于大文件的上传，我们需要进行专门的优化。

## 分片上传的思路

优化大文件上传的一个常见方案是 **分片上传**。简单来说，就是将一个大文件拆分成多个小文件（分片），并行上传这些分片，最后在服务端将这些分片合并成原来的大文件。

### 为什么分片上传更快？

假设我们将 1GB 的文件拆分成 10 个 100MB 的小文件，并行上传这些小文件。由于网络带宽的利用率更高，上传速度会显著提升。等所有分片上传完成后，服务端再将这些分片合并成一个完整的文件。

## 如何实现分片上传？

### 1. 文件分片

在浏览器中，`Blob` 对象有一个 `slice` 方法，可以用来截取某个范围的数据。而 `File` 对象本质上就是一种 `Blob`，因此我们可以通过 `slice` 方法对文件进行分片。

```javascript
const chunkSize = 20 * 1024 // 每个分片大小为 20KB
const file = fileInput.files[0] // 获取用户选择的文件

const chunks = []
let startPos = 0
while (startPos < file.size) {
  chunks.push(file.slice(startPos, startPos + chunkSize))
  startPos += chunkSize
}
```

在上面的代码中，我们将文件按 20KB 的大小进行分片，并将每个分片存入 `chunks` 数组中。

### 2. 分片上传

接下来，我们需要将这些分片逐个上传到服务端。可以通过 `FormData` 将每个分片封装成一个请求，并使用 `axios` 发送 POST 请求。

```javascript
chunks.map((chunk, index) => {
  const data = new FormData()
  data.set('name', file.name + '-' + index) // 分片名称
  data.append('files', chunk) // 分片数据
  axios.post('http://localhost:3000/upload', data)
})
```

每个分片的名称由文件名和分片索引组成，确保每个分片在服务端都有唯一的标识。

### 3. 服务端接收分片

在服务端，我们使用 `NestJS` 框架来处理上传的分片。通过 `@UseInterceptors` 和 `multer` 中间件，我们可以轻松接收上传的文件。

```typescript
@Post('upload')
@UseInterceptors(FilesInterceptor('files', 20, { dest: 'uploads' }))
uploadFiles(@UploadedFiles() files: Array<Express.Multer.File>, @Body() body: { name: string }) {
    const fileName = body.name.match(/(.+)\-\d+$/)[1]; // 提取文件名
    const chunkDir = 'uploads/chunks_' + fileName;

    if (!fs.existsSync(chunkDir)) {
        fs.mkdirSync(chunkDir); // 创建分片目录
    }
    fs.cpSync(files[0].path, chunkDir + '/' + body.name); // 移动分片到目录
    fs.rmSync(files[0].path); // 删除临时文件
}
```

在这里，我们将每个分片保存到一个以 `chunks_文件名` 命名的目录中，确保分片不会冲突。

### 4. 合并分片

当所有分片上传完成后，前端需要发送一个请求，通知服务端进行分片合并。服务端通过 `fs.createWriteStream` 方法，将每个分片按照顺序写入到同一个文件中。

```typescript
@Get('merge')
merge(@Query('name') name: string) {
    const chunkDir = 'uploads/chunks_' + name;
    const files = fs.readdirSync(chunkDir);

    let startPos = 0;
    files.map(file => {
        const filePath = chunkDir + '/' + file;
        const stream = fs.createReadStream(filePath);
        stream.pipe(fs.createWriteStream('uploads/' + name, { start: startPos }));
        startPos += fs.statSync(filePath).size;
    });

    // 合并完成后删除分片目录
    fs.rm(chunkDir, { recursive: true }, () => {});
}
```

在合并完成后，我们还可以删除分片目录，节省存储空间。

### 5. 前端调用合并接口

当所有分片上传完成后，前端可以通过 `Promise.all` 等待所有上传请求完成，然后调用合并接口。

```javascript
const tasks = []
chunks.map((chunk, index) => {
  const data = new FormData()
  data.set('name', randomStr + '_' + file.name + '-' + index)
  data.append('files', chunk)
  tasks.push(axios.post('http://localhost:3000/upload', data))
})
await Promise.all(tasks) // 等待所有分片上传完成
axios.get('http://localhost:3000/merge?name=' + randomStr + '_' + file.name) // 调用合并接口
```

## 进度条的实现

为了提升用户体验，我们还可以在前端实现一个上传进度条。`axios` 提供了 `onUploadProgress` 选项，可以用来监听上传进度。

```javascript
axios.post('http://localhost:3000/upload', data, {
  onUploadProgress: function (progressEvent) {
    const percentCompleted = Math.round((progressEvent.loaded * 100) / progressEvent.total)
    console.log('上传进度：' + percentCompleted + '%')
  },
})
```

通过这种方式，用户可以实时看到上传进度，进一步提升体验。

## 总结

当文件较大时，直接上传会导致速度慢、体验差。通过分片上传的方式，我们可以将大文件拆分成多个小分片并行上传，极大地提升了上传速度。服务端接收分片后，将其保存到指定目录，最后通过合并接口将分片合并成完整的文件。

这种分片上传的方案不仅提升了上传效率，还能在网络不稳定的情况下进行断点续传，进一步提升了用户体验。阿里云等大厂的文件上传服务也是基于类似的原理实现的。

通过本文的介绍，相信你已经掌握了大文件分片上传的基本原理和实现方法。希望这篇文章对你有所帮助！
